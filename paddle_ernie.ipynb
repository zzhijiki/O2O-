{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already up-to-date: paddlehub in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (3.7.9)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (4.1.1.26)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (0.26.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: gunicorn>=19.10.0; sys_platform != \"win32\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (20.0.4)\n",
      "Requirement already satisfied, skipping upgrade: tb-paddle in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (0.3.6)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet==3.0.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: cma==2.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (0.1.85)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub) (6.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub) (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.2.0,>=2.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints<0.4.0,>=0.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.6.0->paddlehub) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (1.26.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: moviepy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tb-paddle->paddlehub) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->paddlehub) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0,>=4.11.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: proglog<=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: decorator<5.0,>=4.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: imageio<3.0,>=2.5; python_version >= \"3.4\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: imageio-ffmpeg>=0.2.0; python_version >= \"3.4\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->paddlehub) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub) (0.4.8)\n",
      "Module ernie already installed in /home/aistudio/.paddlehub/modules/ernie\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlehub -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "#下载ernie的module\n",
    "!hub install ernie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\r\n",
    "\r\n",
    "from paddle.fluid.framework import switch_main_program\r\n",
    "import paddlehub \r\n",
    "import paddle.fluid as fluid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 19:43:56,204] [    INFO] - Installing ernie module\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:43:56,224] [    INFO] - Module ernie already installed in /home/aistudio/.paddlehub/modules/ernie\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "module = paddlehub.Module(name='ernie')\r\n",
    "# dataset = hub.dataset.ChnSentiCorp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "如果想尝试其他语义模型（如ernie_tiny, RoBERTa等），只需要更换Module中的`name`参数即可.\n",
    "\n",
    "   模型名                           | PaddleHub Module\n",
    "---------------------------------- | :------:\n",
    "ERNIE, Chinese                     | `hub.Module(name='ernie')`\n",
    "ERNIE 2.0 Tiny, Chinese            | `hub.Module(name='ernie_tiny')`\n",
    "ERNIE 2.0 Base, English            | `hub.Module(name='ernie_v2_eng_base')`\n",
    "ERNIE 2.0 Large, English           | `hub.Module(name='ernie_v2_eng_large')`\n",
    "RoBERTa-Large, Chinese             | `hub.Module(name='roberta_wwm_ext_chinese_L-24_H-1024_A-16')`\n",
    "RoBERTa-Base, Chinese              | `hub.Module(name='roberta_wwm_ext_chinese_L-12_H-768_A-12')`\n",
    "BERT-Base, Uncased                 | `hub.Module(name='bert_uncased_L-12_H-768_A-12')`\n",
    "BERT-Large, Uncased                | `hub.Module(name='bert_uncased_L-24_H-1024_A-16')`\n",
    "BERT-Base, Cased                   | `hub.Module(name='bert_cased_L-12_H-768_A-12')`\n",
    "BERT-Large, Cased                  | `hub.Module(name='bert_cased_L-24_H-1024_A-16')`\n",
    "BERT-Base, Multilingual Cased      | `hub.Module(nane='bert_multi_cased_L-12_H-768_A-12')`\n",
    "BERT-Base, Chinese                 | `hub.Module(name='bert_chinese_L-12_H-768_A-12')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "如果想加载**自定义数据集**完成迁移学习，详细参见[自定义数据集](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub%E9%80%82%E9%85%8D%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%88%90FineTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### train Dataset\n",
    "\n",
    "f=open(\"data/train_split.csv\",\"r\")\n",
    "f2=open(\"data/train.tsv\",\"w\",encoding= \"utf-8\")\n",
    "for index,line in enumerate(f.readlines()):\n",
    "    if index==0:\n",
    "        continue\n",
    "    line= line.replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\",\")\n",
    "    label=line[0]\n",
    "    comment=line[1]\n",
    "    string=comment+\"\\t\"+label+\"\\n\"\n",
    "    f2.writelines(string)\n",
    "f.close()\n",
    "f2.close()\n",
    "\n",
    "#### valid Dataset\n",
    "f=open(\"data/valid_split.csv\",\"r\")\n",
    "f2=open(\"data/dev.tsv\",\"w\",encoding= \"utf-8\")\n",
    "for index,line in enumerate(f.readlines()):\n",
    "    if index==0:\n",
    "        continue\n",
    "    line= line.replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\",\")\n",
    "    label=line[0]\n",
    "    comment=line[1]\n",
    "    string=comment+\"\\t\"+label+\"\\n\"\n",
    "    f2.writelines(string)\n",
    "f.close()\n",
    "f2.close()\n",
    "\n",
    "#### predict Dataset\n",
    "f=open(\"data/test_new.csv\",\"r\")\n",
    "f2=open(\"data/predict.tsv\",\"w\",encoding= \"utf-8\")\n",
    "for index,line in enumerate(f.readlines()):\n",
    "    if index==0:\n",
    "        continue\n",
    "    line= line.replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\",\")\n",
    "    label=line[0]\n",
    "    comment=line[1]\n",
    "    string=comment+\"\\n\"\n",
    "    f2.writelines(string)\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlehub.dataset.base_nlp_dataset import BaseNLPDataset\r\n",
    "\r\n",
    "class DemoDataset(BaseNLPDataset):\r\n",
    "    \"\"\"DemoDataset\"\"\"\r\n",
    "    def __init__(self):\r\n",
    "        # 数据集存放位置\r\n",
    "        self.dataset_dir = \"data\"\r\n",
    "        super(DemoDataset, self).__init__(\r\n",
    "            base_path=self.dataset_dir,\r\n",
    "            train_file=\"train.tsv\",\r\n",
    "            dev_file=\"dev.tsv\",\r\n",
    "            test_file=\"dev.tsv\",\r\n",
    "            # 如果还有预测数据（不需要文本类别label），可以放在predict.tsv\r\n",
    "            # predict_file=\"predict.tsv\",\r\n",
    "            train_file_with_header=False,\r\n",
    "            dev_file_with_header=False,\r\n",
    "            test_file_with_header=False,\r\n",
    "            # predict_file_with_header=False,\r\n",
    "            # 数据集类别集合\r\n",
    "            label_list=[\"0\", \"1\"])\r\n",
    "dataset = DemoDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、生成Reader\n",
    "\n",
    "接着生成一个文本分类的reader，reader负责将dataset的数据进行预处理，首先对文本进行切词，接着以特定格式组织并输入给模型进行训练。\n",
    "\n",
    "`ClassifyReader`的参数有以下三个：\n",
    "* `dataset`: 传入PaddleHub Dataset;\n",
    "* `vocab_path`: 传入ERNIE/BERT模型对应的词表文件路径;\n",
    "* `max_seq_len`: ERNIE模型的最大序列长度，若序列长度不足，会通过padding方式补到`max_seq_len`, 若序列长度大于该值，则会以截断方式让序列长度为`max_seq_len`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aistudio/.paddlehub/modules/ernie/assets/vocab.txt'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.get_vocab_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 19:44:06,970] [    INFO] - Dataset label map = {'0': 0, '1': 1}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reader = paddlehub.reader.ClassifyReader(\r\n",
    "    dataset=dataset,\r\n",
    "    vocab_path=module.get_vocab_path(),\r\n",
    "    max_seq_len=256)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**NOTE：** Reader参数max_seq_len、moduel的context接口参数max_seq_len三者应该保持一致，最大序列长度`max_seq_len`是可以调整的参数，建议值128，根据任务文本长度不同可以调整该值，但最大不超过512。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、选择Fine-Tune优化策略\n",
    "适用于ERNIE/BERT这类Transformer模型的迁移优化策略为`AdamWeightDecayStrategy`。详情请查看[Strategy](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Strategy)。\n",
    "\n",
    "`AdamWeightDecayStrategy`的参数有以下三个：\n",
    " * `learning_rate`: 最大学习率\n",
    " * `lr_scheduler`: 有`linear_decay`和`noam_decay`两种衰减策略可选\n",
    " * `warmup_proprotion`: 训练预热的比例，若设置为0.1, 则会在前10%的训练step中学习率逐步提升到`learning_rate`\n",
    " * `weight_decay`: 权重衰减，类似模型正则项策略，避免模型overfitting\n",
    " * `optimizer_name`: 优化器名称，使用Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、选择运行时配置\n",
    "\n",
    "在进行Finetune前，我们可以设置一些运行时的配置，例如如下代码中的配置，表示：\n",
    "\n",
    "* `use_cuda`：设置为False表示使用CPU进行训练。如果您本机支持GPU，且安装的是GPU版本的PaddlePaddle，我们建议您将这个选项设置为True；\n",
    "\n",
    "* `epoch`：要求Finetune的任务只遍历1次训练集；\n",
    "\n",
    "* `batch_size`：每次训练的时候，给模型输入的每批数据大小为32，模型训练时能够并行处理批数据，因此batch_size越大，训练的效率越高，但是同时带来了内存的负荷，过大的batch_size可能导致内存不足而无法训练，因此选择一个合适的batch_size是很重要的一步；\n",
    "\n",
    "* `log_interval`：每隔10 step打印一次训练日志；\n",
    "\n",
    "* `eval_interval`：每隔50 step在验证集上进行一次性能评估；\n",
    "\n",
    "* `checkpoint_dir`：将训练的参数和数据保存到ernie_txt_cls_turtorial_demo目录中；\n",
    "\n",
    "* `strategy`：使用DefaultFinetuneStrategy策略进行finetune；\n",
    "\n",
    "更多运行配置，请查看[RunConfig](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-RunConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 19:44:10,343] [    INFO] - Checkpoint dir: ernie_txt_cls_turtorial_demo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "strategy = paddlehub.AdamWeightDecayStrategy(\r\n",
    "    weight_decay=0.001,\r\n",
    "    warmup_proportion=0.1,\r\n",
    "    learning_rate=5e-5)\r\n",
    "\r\n",
    "\r\n",
    "config = paddlehub.RunConfig(\r\n",
    "    use_cuda=True,\r\n",
    "    num_epoch=8,\r\n",
    "    checkpoint_dir=\"ernie_txt_cls_turtorial_demo\",\r\n",
    "    batch_size=16,\r\n",
    "    eval_interval=50,\r\n",
    "    strategy=strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PaddleHub提供了许多优化策略，如`AdamWeightDecayStrategy`、`ULMFiTStrategy`、`DefaultFinetuneStrategy`等，详细信息参见[策略](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、组建Finetune Task\n",
    "\n",
    "有了合适的预训练模型和准备要迁移的数据集后，我们开始组建一个Task。\n",
    "\n",
    "1. 获取module的上下文环境，包括输入和输出的变量，以及Paddle Program；\n",
    "2. 从输出变量中找到用于情感分类的文本特征pooled_output；\n",
    "3. 在pooled_output后面接入一个全连接层，生成Task；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 19:44:13,255] [    INFO] - Set maximum sequence length of input tensor to 256\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:13,257] [    INFO] - The shape of input tensor[input_ids] set to [-1, 256, 1]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:13,257] [    INFO] - The shape of input tensor[position_ids] set to [-1, 256, 1]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:13,258] [    INFO] - The shape of input tensor[segment_ids] set to [-1, 256, 1]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:13,258] [    INFO] - The shape of input tensor[input_mask] set to [-1, 256, 1]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:13,259] [    INFO] - 199 pretrained paramaters loaded by PaddleHub\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs, program = module.context(\r\n",
    "    trainable=True, max_seq_len=256)\r\n",
    "\r\n",
    "# Use \"pooled_output\" for classification tasks on an entire sentence.\r\n",
    "pooled_output = outputs[\"pooled_output\"]\r\n",
    "\r\n",
    "feed_list = [\r\n",
    "    inputs[\"input_ids\"].name,\r\n",
    "    inputs[\"position_ids\"].name,\r\n",
    "    inputs[\"segment_ids\"].name,\r\n",
    "    inputs[\"input_mask\"].name,\r\n",
    "]\r\n",
    "\r\n",
    "cls_task = paddlehub.TextClassifierTask(\r\n",
    "    data_reader=reader,\r\n",
    "    feature=pooled_output,\r\n",
    "    feed_list=feed_list,\r\n",
    "    num_classes=dataset.num_labels,\r\n",
    "    metrics_choices=[\"f1\",\"matthews\",\"acc\"],\r\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "如果想改变迁移任务组网，详细参见[自定义迁移任务](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub:-%E8%87%AA%E5%AE%9A%E4%B9%89Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、开始Finetune\r\n",
    "\r\n",
    "我们选择`finetune_and_eval`接口来进行模型训练，这个接口在finetune的过程中，会周期性的进行模型效果的评估，以便我们了解整个训练过程的性能变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 19:44:15,658-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "\u001b[32m[2020-02-28 19:44:15,917] [    INFO] - Strategy with scheduler: {'warmup': 0.1, 'linear_decay': {'start_point': 0.1, 'end_learning_rate': 0}, 'noam_decay': False, 'discriminative': {'blocks': 0, 'factor': 2.6}, 'gradual_unfreeze': 0, 'slanted_triangle': {'cut_fraction': 0.0, 'ratio': 32}}, regularization: {'L2': 0.0, 'L2SP': 0.0, 'weight_decay': 0.001} and clip: {'GlobalNorm': 1.0, 'Norm': 0.0}\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:20,133] [    INFO] - Try loading checkpoint from ernie_txt_cls_turtorial_demo/ckpt.meta\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:20,134] [    INFO] - PaddleHub model checkpoint not found, start from scratch...\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:20,204] [    INFO] - PaddleHub finetune start\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:24,156] [   TRAIN] - step 10 / 4000: loss=0.50350 f1=0.00000 matthews=-0.05949 acc=0.82500 [step/sec: 2.54]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:27,114] [   TRAIN] - step 20 / 4000: loss=0.45047 f1=0.00000 matthews=-0.03083 acc=0.86250 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:30,075] [   TRAIN] - step 30 / 4000: loss=0.48173 f1=0.00000 matthews=0.00000 acc=0.82500 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:33,031] [   TRAIN] - step 40 / 4000: loss=0.41667 f1=0.00000 matthews=0.00000 acc=0.86875 [step/sec: 3.39]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:35,990] [   TRAIN] - step 50 / 4000: loss=0.37871 f1=0.00000 matthews=0.00000 acc=0.86875 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:44:35,991] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "2020-02-28 19:44:36,559-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "share_vars_from is set, scope is ignored.\n",
      "\u001b[34m[2020-02-28 19:44:47,697] [    EVAL] - [dev dataset evaluation result] loss=0.39273 f1=0.00000 matthews=0.00000 acc=0.84900 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:44:47,698] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.00000]\u001b[0m\n",
      "2020-02-28 19:44:48,268-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "\u001b[36m[2020-02-28 19:44:52,348] [   TRAIN] - step 60 / 4000: loss=0.36653 f1=0.00000 matthews=0.00000 acc=0.86250 [step/sec: 3.39]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:55,302] [   TRAIN] - step 70 / 4000: loss=0.41314 f1=0.00000 matthews=0.00000 acc=0.82500 [step/sec: 3.39]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:44:58,255] [   TRAIN] - step 80 / 4000: loss=0.37511 f1=0.00000 matthews=0.00000 acc=0.83750 [step/sec: 3.39]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:01,205] [   TRAIN] - step 90 / 4000: loss=0.29908 f1=0.00000 matthews=0.00000 acc=0.88125 [step/sec: 3.39]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:04,166] [   TRAIN] - step 100 / 4000: loss=0.27591 f1=0.09091 matthews=0.12757 acc=0.87500 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:45:04,167] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:45:14,985] [    EVAL] - [dev dataset evaluation result] loss=0.26133 f1=0.04516 matthews=0.12814 acc=0.85200 [step/sec: 11.57]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:45:14,986] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.04516]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:18,936] [   TRAIN] - step 110 / 4000: loss=0.28504 f1=0.38889 matthews=0.45461 acc=0.86250 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:21,899] [   TRAIN] - step 120 / 4000: loss=0.22221 f1=0.57778 matthews=0.54622 acc=0.88125 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:24,865] [   TRAIN] - step 130 / 4000: loss=0.24540 f1=0.69841 matthews=0.62579 acc=0.88125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:27,828] [   TRAIN] - step 140 / 4000: loss=0.20490 f1=0.78689 matthews=0.74499 acc=0.91875 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:30,791] [   TRAIN] - step 150 / 4000: loss=0.17683 f1=0.80000 matthews=0.75385 acc=0.92500 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:45:30,792] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:45:41,680] [    EVAL] - [dev dataset evaluation result] loss=0.14919 f1=0.80435 matthews=0.76908 acc=0.93700 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:45:41,681] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.80435]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:45,625] [   TRAIN] - step 160 / 4000: loss=0.20607 f1=0.68966 matthews=0.62356 acc=0.88750 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:48,588] [   TRAIN] - step 170 / 4000: loss=0.16181 f1=0.68571 matthews=0.64749 acc=0.93125 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:51,556] [   TRAIN] - step 180 / 4000: loss=0.21506 f1=0.58824 matthews=0.57535 acc=0.91250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:54,528] [   TRAIN] - step 190 / 4000: loss=0.20113 f1=0.79365 matthews=0.74711 acc=0.91875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:45:57,494] [   TRAIN] - step 200 / 4000: loss=0.08083 f1=0.87500 matthews=0.86975 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:45:57,495] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:46:08,396] [    EVAL] - [dev dataset evaluation result] loss=0.10463 f1=0.88070 matthews=0.86305 acc=0.96600 [step/sec: 11.51]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:46:08,397] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.88070]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:12,330] [   TRAIN] - step 210 / 4000: loss=0.21802 f1=0.74419 matthews=0.70699 acc=0.93125 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:15,290] [   TRAIN] - step 220 / 4000: loss=0.18074 f1=0.85185 matthews=0.82264 acc=0.95000 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:18,261] [   TRAIN] - step 230 / 4000: loss=0.16959 f1=0.79167 matthews=0.75885 acc=0.93750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:21,224] [   TRAIN] - step 240 / 4000: loss=0.11114 f1=0.84615 matthews=0.81722 acc=0.95000 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:24,191] [   TRAIN] - step 250 / 4000: loss=0.13974 f1=0.79070 matthews=0.76562 acc=0.94375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:46:24,192] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:46:35,086] [    EVAL] - [dev dataset evaluation result] loss=0.12104 f1=0.85888 matthews=0.83544 acc=0.95350 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:38,051] [   TRAIN] - step 260 / 4000: loss=0.11071 f1=0.91176 matthews=0.88860 acc=0.96250 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:41,018] [   TRAIN] - step 270 / 4000: loss=0.15742 f1=0.87500 matthews=0.85401 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:43,984] [   TRAIN] - step 280 / 4000: loss=0.15204 f1=0.84615 matthews=0.81722 acc=0.95000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:46,953] [   TRAIN] - step 290 / 4000: loss=0.09146 f1=0.88889 matthews=0.87101 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:46:49,921] [   TRAIN] - step 300 / 4000: loss=0.09698 f1=0.88889 matthews=0.86723 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:46:49,922] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:47:00,734] [    EVAL] - [dev dataset evaluation result] loss=0.18988 f1=0.80282 matthews=0.77415 acc=0.93000 [step/sec: 11.57]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:03,707] [   TRAIN] - step 310 / 4000: loss=0.08224 f1=0.94340 matthews=0.93240 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:06,675] [   TRAIN] - step 320 / 4000: loss=0.03266 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:09,642] [   TRAIN] - step 330 / 4000: loss=0.04754 f1=0.93023 matthews=0.91974 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:12,612] [   TRAIN] - step 340 / 4000: loss=0.21821 f1=0.74286 matthews=0.72129 acc=0.94375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:15,579] [   TRAIN] - step 350 / 4000: loss=0.13980 f1=0.86364 matthews=0.84190 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:47:15,580] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:47:26,445] [    EVAL] - [dev dataset evaluation result] loss=0.11047 f1=0.90909 matthews=0.89342 acc=0.97300 [step/sec: 11.54]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:47:26,446] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.90909]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:30,381] [   TRAIN] - step 360 / 4000: loss=0.11465 f1=0.90909 matthews=0.89588 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:33,347] [   TRAIN] - step 370 / 4000: loss=0.06632 f1=0.94545 matthews=0.93436 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:36,318] [   TRAIN] - step 380 / 4000: loss=0.15109 f1=0.84211 matthews=0.82083 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:39,290] [   TRAIN] - step 390 / 4000: loss=0.14701 f1=0.77419 matthews=0.76286 acc=0.95625 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:42,259] [   TRAIN] - step 400 / 4000: loss=0.15976 f1=0.81081 matthews=0.79589 acc=0.95625 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:47:42,260] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:47:53,142] [    EVAL] - [dev dataset evaluation result] loss=0.07691 f1=0.91765 matthews=0.90340 acc=0.97550 [step/sec: 11.56]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:47:53,143] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.91765]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:47:57,350] [   TRAIN] - step 410 / 4000: loss=0.07107 f1=0.88889 matthews=0.87657 acc=0.97500 [step/sec: 3.38]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:00,319] [   TRAIN] - step 420 / 4000: loss=0.07308 f1=0.93103 matthews=0.91660 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:03,292] [   TRAIN] - step 430 / 4000: loss=0.15273 f1=0.88889 matthews=0.87447 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:06,263] [   TRAIN] - step 440 / 4000: loss=0.16042 f1=0.87273 matthews=0.84825 acc=0.95625 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:09,232] [   TRAIN] - step 450 / 4000: loss=0.03391 f1=0.98039 matthews=0.97694 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:48:09,233] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:48:20,072] [    EVAL] - [dev dataset evaluation result] loss=0.08471 f1=0.92386 matthews=0.91097 acc=0.97750 [step/sec: 11.60]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:48:20,073] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.92386]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:24,028] [   TRAIN] - step 460 / 4000: loss=0.17223 f1=0.85714 matthews=0.83687 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:26,999] [   TRAIN] - step 470 / 4000: loss=0.11689 f1=0.89362 matthews=0.87785 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:29,971] [   TRAIN] - step 480 / 4000: loss=0.11350 f1=0.89362 matthews=0.87785 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:32,942] [   TRAIN] - step 490 / 4000: loss=0.06707 f1=0.94737 matthews=0.93618 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:35,913] [   TRAIN] - step 500 / 4000: loss=0.09310 f1=0.87179 matthews=0.85741 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:48:35,914] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:48:46,815] [    EVAL] - [dev dataset evaluation result] loss=0.08475 f1=0.91769 matthews=0.90609 acc=0.97650 [step/sec: 11.49]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:49,794] [   TRAIN] - step 510 / 4000: loss=0.03924 f1=0.94737 matthews=0.94028 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:52,763] [   TRAIN] - step 520 / 4000: loss=0.08196 f1=0.90909 matthews=0.89916 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:55,735] [   TRAIN] - step 530 / 4000: loss=0.03827 f1=0.95238 matthews=0.94663 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:48:58,707] [   TRAIN] - step 540 / 4000: loss=0.11928 f1=0.86275 matthews=0.84275 acc=0.95625 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:01,677] [   TRAIN] - step 550 / 4000: loss=0.05894 f1=0.94444 matthews=0.93927 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:49:01,678] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:49:12,581] [    EVAL] - [dev dataset evaluation result] loss=0.09169 f1=0.91388 matthews=0.90198 acc=0.97550 [step/sec: 11.48]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:15,553] [   TRAIN] - step 560 / 4000: loss=0.08397 f1=0.90476 matthews=0.89591 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:18,525] [   TRAIN] - step 570 / 4000: loss=0.08073 f1=0.92308 matthews=0.90815 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:21,496] [   TRAIN] - step 580 / 4000: loss=0.07965 f1=0.94915 matthews=0.93952 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:24,467] [   TRAIN] - step 590 / 4000: loss=0.04037 f1=0.96000 matthews=0.95368 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:27,439] [   TRAIN] - step 600 / 4000: loss=0.05557 f1=0.96154 matthews=0.95408 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:49:27,441] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:49:38,341] [    EVAL] - [dev dataset evaluation result] loss=0.12058 f1=0.89912 matthews=0.88547 acc=0.97150 [step/sec: 11.47]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:41,311] [   TRAIN] - step 610 / 4000: loss=0.11904 f1=0.92000 matthews=0.90623 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:44,280] [   TRAIN] - step 620 / 4000: loss=0.08392 f1=0.93333 matthews=0.92526 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:47,250] [   TRAIN] - step 630 / 4000: loss=0.07629 f1=0.92308 matthews=0.91210 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:50,215] [   TRAIN] - step 640 / 4000: loss=0.14465 f1=0.84000 matthews=0.81916 acc=0.95000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:49:53,185] [   TRAIN] - step 650 / 4000: loss=0.07893 f1=0.88889 matthews=0.88192 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:49:53,187] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:50:04,013] [    EVAL] - [dev dataset evaluation result] loss=0.07882 f1=0.92808 matthews=0.91654 acc=0.97900 [step/sec: 11.56]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:50:04,015] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.92808]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:07,942] [   TRAIN] - step 660 / 4000: loss=0.03449 f1=0.93333 matthews=0.92899 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:10,914] [   TRAIN] - step 670 / 4000: loss=0.12639 f1=0.89286 matthews=0.87098 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:13,885] [   TRAIN] - step 680 / 4000: loss=0.06339 f1=0.93023 matthews=0.91974 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:16,856] [   TRAIN] - step 690 / 4000: loss=0.06223 f1=0.92593 matthews=0.91182 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:19,828] [   TRAIN] - step 700 / 4000: loss=0.11388 f1=0.93151 matthews=0.91499 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:50:19,829] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:50:30,594] [    EVAL] - [dev dataset evaluation result] loss=0.07536 f1=0.92749 matthews=0.91509 acc=0.97850 [step/sec: 11.64]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:33,566] [   TRAIN] - step 710 / 4000: loss=0.04564 f1=0.95833 matthews=0.95214 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:36,538] [   TRAIN] - step 720 / 4000: loss=0.09048 f1=0.91667 matthews=0.90308 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:39,512] [   TRAIN] - step 730 / 4000: loss=0.14775 f1=0.91228 matthews=0.89856 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:42,484] [   TRAIN] - step 740 / 4000: loss=0.07634 f1=0.91228 matthews=0.89856 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:45,457] [   TRAIN] - step 750 / 4000: loss=0.06942 f1=0.91304 matthews=0.89964 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:50:45,458] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:50:56,357] [    EVAL] - [dev dataset evaluation result] loss=0.08339 f1=0.92724 matthews=0.91494 acc=0.97850 [step/sec: 11.48]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:50:59,331] [   TRAIN] - step 760 / 4000: loss=0.14002 f1=0.85714 matthews=0.83556 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:02,300] [   TRAIN] - step 770 / 4000: loss=0.10129 f1=0.91892 matthews=0.91223 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:05,275] [   TRAIN] - step 780 / 4000: loss=0.06550 f1=0.93023 matthews=0.91974 acc=0.98125 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:08,249] [   TRAIN] - step 790 / 4000: loss=0.10406 f1=0.87805 matthews=0.86048 acc=0.96875 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:11,222] [   TRAIN] - step 800 / 4000: loss=0.04190 f1=0.95833 matthews=0.95098 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:51:11,223] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:51:22,032] [    EVAL] - [dev dataset evaluation result] loss=0.08891 f1=0.92512 matthews=0.91190 acc=0.97750 [step/sec: 11.58]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:25,005] [   TRAIN] - step 810 / 4000: loss=0.11482 f1=0.87500 matthews=0.85294 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:27,976] [   TRAIN] - step 820 / 4000: loss=0.00646 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:30,943] [   TRAIN] - step 830 / 4000: loss=0.06933 f1=0.95455 matthews=0.94863 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:33,915] [   TRAIN] - step 840 / 4000: loss=0.07700 f1=0.94340 matthews=0.93240 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:36,886] [   TRAIN] - step 850 / 4000: loss=0.06517 f1=0.94545 matthews=0.93436 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:51:36,887] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:51:47,785] [    EVAL] - [dev dataset evaluation result] loss=0.09064 f1=0.92734 matthews=0.91636 acc=0.97900 [step/sec: 11.48]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:50,755] [   TRAIN] - step 860 / 4000: loss=0.03224 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:53,729] [   TRAIN] - step 870 / 4000: loss=0.14307 f1=0.88000 matthews=0.86182 acc=0.96250 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:56,701] [   TRAIN] - step 880 / 4000: loss=0.14517 f1=0.87179 matthews=0.85741 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:51:59,675] [   TRAIN] - step 890 / 4000: loss=0.04754 f1=0.96296 matthews=0.95641 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:02,646] [   TRAIN] - step 900 / 4000: loss=0.02784 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:52:02,648] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:52:13,494] [    EVAL] - [dev dataset evaluation result] loss=0.11342 f1=0.92573 matthews=0.91436 acc=0.97850 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:16,464] [   TRAIN] - step 910 / 4000: loss=0.08848 f1=0.93023 matthews=0.92246 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:19,436] [   TRAIN] - step 920 / 4000: loss=0.11084 f1=0.92593 matthews=0.91182 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:22,409] [   TRAIN] - step 930 / 4000: loss=0.06767 f1=0.91667 matthews=0.90196 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:25,380] [   TRAIN] - step 940 / 4000: loss=0.02738 f1=0.96296 matthews=0.95641 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:28,349] [   TRAIN] - step 950 / 4000: loss=0.05306 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:52:28,350] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:52:39,165] [    EVAL] - [dev dataset evaluation result] loss=0.07965 f1=0.92991 matthews=0.91859 acc=0.97950 [step/sec: 11.60]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:52:39,166] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.92991]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:43,129] [   TRAIN] - step 960 / 4000: loss=0.11400 f1=0.89362 matthews=0.87558 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:46,100] [   TRAIN] - step 970 / 4000: loss=0.06626 f1=0.95238 matthews=0.94090 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:49,069] [   TRAIN] - step 980 / 4000: loss=0.08219 f1=0.91429 matthews=0.90423 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:52,040] [   TRAIN] - step 990 / 4000: loss=0.02690 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:52:55,012] [   TRAIN] - step 1000 / 4000: loss=0.09524 f1=0.88372 matthews=0.86859 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:52:55,014] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:53:05,921] [    EVAL] - [dev dataset evaluation result] loss=0.09448 f1=0.91749 matthews=0.90277 acc=0.97500 [step/sec: 11.51]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:08,909] [   TRAIN] - step 1010 / 4000: loss=0.07156 f1=0.92308 matthews=0.91280 acc=0.98125 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:11,878] [   TRAIN] - step 1020 / 4000: loss=0.02400 f1=0.91667 matthews=0.90991 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:14,849] [   TRAIN] - step 1030 / 4000: loss=0.07921 f1=0.93103 matthews=0.91660 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:17,819] [   TRAIN] - step 1040 / 4000: loss=0.02422 f1=0.96552 matthews=0.96278 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:20,788] [   TRAIN] - step 1050 / 4000: loss=0.02855 f1=0.96429 matthews=0.95671 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:53:20,789] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:53:31,554] [    EVAL] - [dev dataset evaluation result] loss=0.10267 f1=0.91349 matthews=0.90016 acc=0.97500 [step/sec: 11.65]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:34,527] [   TRAIN] - step 1060 / 4000: loss=0.02675 f1=0.98305 matthews=0.97943 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:37,498] [   TRAIN] - step 1070 / 4000: loss=0.09822 f1=0.93103 matthews=0.91577 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:40,469] [   TRAIN] - step 1080 / 4000: loss=0.03810 f1=0.95455 matthews=0.94730 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:43,441] [   TRAIN] - step 1090 / 4000: loss=0.02040 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:53:46,412] [   TRAIN] - step 1100 / 4000: loss=0.02305 f1=0.98113 matthews=0.97764 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:53:46,413] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:53:57,303] [    EVAL] - [dev dataset evaluation result] loss=0.10528 f1=0.92123 matthews=0.90852 acc=0.97700 [step/sec: 11.49]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:00,275] [   TRAIN] - step 1110 / 4000: loss=0.01445 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:03,246] [   TRAIN] - step 1120 / 4000: loss=0.02342 f1=0.98305 matthews=0.97943 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:06,220] [   TRAIN] - step 1130 / 4000: loss=0.07692 f1=0.93617 matthews=0.92783 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:09,193] [   TRAIN] - step 1140 / 4000: loss=0.00712 f1=0.97143 matthews=0.96842 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:12,162] [   TRAIN] - step 1150 / 4000: loss=0.00106 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:54:12,164] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:54:22,937] [    EVAL] - [dev dataset evaluation result] loss=0.13602 f1=0.91854 matthews=0.90620 acc=0.97650 [step/sec: 11.61]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:25,908] [   TRAIN] - step 1160 / 4000: loss=0.04128 f1=0.96429 matthews=0.95762 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:28,877] [   TRAIN] - step 1170 / 4000: loss=0.00630 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:31,848] [   TRAIN] - step 1180 / 4000: loss=0.02873 f1=0.97297 matthews=0.96990 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:34,821] [   TRAIN] - step 1190 / 4000: loss=0.05300 f1=0.96667 matthews=0.95897 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:37,793] [   TRAIN] - step 1200 / 4000: loss=0.00545 f1=0.98361 matthews=0.97995 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:54:37,794] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:54:48,594] [    EVAL] - [dev dataset evaluation result] loss=0.13662 f1=0.92177 matthews=0.90876 acc=0.97700 [step/sec: 11.61]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:51,567] [   TRAIN] - step 1210 / 4000: loss=0.00147 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:54,537] [   TRAIN] - step 1220 / 4000: loss=0.01180 f1=0.96296 matthews=0.95641 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:54:57,510] [   TRAIN] - step 1230 / 4000: loss=0.08565 f1=0.95082 matthews=0.94101 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:00,482] [   TRAIN] - step 1240 / 4000: loss=0.01702 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:03,456] [   TRAIN] - step 1250 / 4000: loss=0.05978 f1=0.96154 matthews=0.95408 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:55:03,457] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:55:14,282] [    EVAL] - [dev dataset evaluation result] loss=0.10185 f1=0.93151 matthews=0.92055 acc=0.98000 [step/sec: 11.56]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:55:14,283] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.93151]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:18,228] [   TRAIN] - step 1260 / 4000: loss=0.04686 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:21,195] [   TRAIN] - step 1270 / 4000: loss=0.08489 f1=0.92308 matthews=0.91280 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:24,165] [   TRAIN] - step 1280 / 4000: loss=0.03796 f1=0.94340 matthews=0.93435 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:27,135] [   TRAIN] - step 1290 / 4000: loss=0.05998 f1=0.95455 matthews=0.94730 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:30,107] [   TRAIN] - step 1300 / 4000: loss=0.06954 f1=0.92857 matthews=0.91695 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:55:30,108] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:55:40,981] [    EVAL] - [dev dataset evaluation result] loss=0.10872 f1=0.91809 matthews=0.90463 acc=0.97600 [step/sec: 11.51]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:43,952] [   TRAIN] - step 1310 / 4000: loss=0.01515 f1=0.98039 matthews=0.97694 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:46,922] [   TRAIN] - step 1320 / 4000: loss=0.02613 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:49,892] [   TRAIN] - step 1330 / 4000: loss=0.04927 f1=0.98113 matthews=0.97764 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:52,865] [   TRAIN] - step 1340 / 4000: loss=0.16547 f1=0.88372 matthews=0.86599 acc=0.96875 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:55:55,838] [   TRAIN] - step 1350 / 4000: loss=0.08508 f1=0.91892 matthews=0.90875 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:55:55,839] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:56:06,683] [    EVAL] - [dev dataset evaluation result] loss=0.09130 f1=0.91653 matthews=0.90157 acc=0.97450 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:09,651] [   TRAIN] - step 1360 / 4000: loss=0.02011 f1=0.98361 matthews=0.97995 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:12,624] [   TRAIN] - step 1370 / 4000: loss=0.01589 f1=0.96154 matthews=0.95408 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:15,597] [   TRAIN] - step 1380 / 4000: loss=0.02974 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:18,571] [   TRAIN] - step 1390 / 4000: loss=0.02887 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:21,541] [   TRAIN] - step 1400 / 4000: loss=0.02710 f1=0.95455 matthews=0.94863 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:56:21,543] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:56:32,381] [    EVAL] - [dev dataset evaluation result] loss=0.10733 f1=0.92255 matthews=0.91039 acc=0.97750 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:35,355] [   TRAIN] - step 1410 / 4000: loss=0.05726 f1=0.96154 matthews=0.95510 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:38,329] [   TRAIN] - step 1420 / 4000: loss=0.06477 f1=0.92857 matthews=0.91695 acc=0.97500 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:41,299] [   TRAIN] - step 1430 / 4000: loss=0.03471 f1=0.95455 matthews=0.94730 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:44,270] [   TRAIN] - step 1440 / 4000: loss=0.02820 f1=0.97297 matthews=0.96990 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:56:47,242] [   TRAIN] - step 1450 / 4000: loss=0.02112 f1=0.96970 matthews=0.96677 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:56:47,243] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:56:58,129] [    EVAL] - [dev dataset evaluation result] loss=0.09489 f1=0.93023 matthews=0.91788 acc=0.97900 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:01,101] [   TRAIN] - step 1460 / 4000: loss=0.03493 f1=0.96154 matthews=0.95510 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:04,069] [   TRAIN] - step 1470 / 4000: loss=0.00555 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:07,041] [   TRAIN] - step 1480 / 4000: loss=0.00712 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:10,009] [   TRAIN] - step 1490 / 4000: loss=0.01649 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:12,984] [   TRAIN] - step 1500 / 4000: loss=0.05497 f1=0.96296 matthews=0.95641 acc=0.98750 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:57:12,985] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:57:23,830] [    EVAL] - [dev dataset evaluation result] loss=0.12664 f1=0.92667 matthews=0.91375 acc=0.97800 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:26,851] [   TRAIN] - step 1510 / 4000: loss=0.04076 f1=0.95833 matthews=0.95098 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:29,820] [   TRAIN] - step 1520 / 4000: loss=0.00232 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:32,789] [   TRAIN] - step 1530 / 4000: loss=0.00382 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:35,758] [   TRAIN] - step 1540 / 4000: loss=0.02083 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:38,729] [   TRAIN] - step 1550 / 4000: loss=0.00082 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:57:38,730] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:57:49,558] [    EVAL] - [dev dataset evaluation result] loss=0.15926 f1=0.90590 matthews=0.88928 acc=0.97050 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:52,530] [   TRAIN] - step 1560 / 4000: loss=0.00182 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:55,500] [   TRAIN] - step 1570 / 4000: loss=0.06941 f1=0.96296 matthews=0.95641 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:57:58,469] [   TRAIN] - step 1580 / 4000: loss=0.00014 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:01,439] [   TRAIN] - step 1590 / 4000: loss=0.02284 f1=0.97674 matthews=0.97349 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:04,411] [   TRAIN] - step 1600 / 4000: loss=0.07470 f1=0.92683 matthews=0.91938 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:58:04,412] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:58:15,260] [    EVAL] - [dev dataset evaluation result] loss=0.14480 f1=0.90675 matthews=0.89012 acc=0.97100 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:18,231] [   TRAIN] - step 1610 / 4000: loss=0.00390 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:21,202] [   TRAIN] - step 1620 / 4000: loss=0.00127 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:24,171] [   TRAIN] - step 1630 / 4000: loss=0.02580 f1=0.98039 matthews=0.97694 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:27,142] [   TRAIN] - step 1640 / 4000: loss=0.00018 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:30,112] [   TRAIN] - step 1650 / 4000: loss=0.00195 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:58:30,113] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:58:41,018] [    EVAL] - [dev dataset evaluation result] loss=0.13974 f1=0.93220 matthews=0.92084 acc=0.98000 [step/sec: 11.47]\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:58:41,019] [    EVAL] - best model saved to ernie_txt_cls_turtorial_demo/best_model [best f1=0.93220]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:44,959] [   TRAIN] - step 1660 / 4000: loss=0.00022 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:47,928] [   TRAIN] - step 1670 / 4000: loss=0.00048 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:50,895] [   TRAIN] - step 1680 / 4000: loss=0.01890 f1=0.98113 matthews=0.97764 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:53,866] [   TRAIN] - step 1690 / 4000: loss=0.03079 f1=0.98413 matthews=0.98043 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:58:56,838] [   TRAIN] - step 1700 / 4000: loss=0.00057 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:58:56,839] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:59:07,654] [    EVAL] - [dev dataset evaluation result] loss=0.16864 f1=0.90997 matthews=0.89393 acc=0.97200 [step/sec: 11.63]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:10,623] [   TRAIN] - step 1710 / 4000: loss=0.04381 f1=0.94118 matthews=0.93624 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:13,600] [   TRAIN] - step 1720 / 4000: loss=0.00050 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:16,571] [   TRAIN] - step 1730 / 4000: loss=0.01017 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:19,540] [   TRAIN] - step 1740 / 4000: loss=0.00047 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:22,510] [   TRAIN] - step 1750 / 4000: loss=0.00020 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:59:22,511] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:59:33,347] [    EVAL] - [dev dataset evaluation result] loss=0.16507 f1=0.92101 matthews=0.90735 acc=0.97650 [step/sec: 11.54]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:36,318] [   TRAIN] - step 1760 / 4000: loss=0.00096 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:39,291] [   TRAIN] - step 1770 / 4000: loss=0.05502 f1=0.93333 matthews=0.92274 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:42,258] [   TRAIN] - step 1780 / 4000: loss=0.00013 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:45,230] [   TRAIN] - step 1790 / 4000: loss=0.00023 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 19:59:48,205] [   TRAIN] - step 1800 / 4000: loss=0.03300 f1=0.98305 matthews=0.97943 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 19:59:48,206] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 19:59:59,123] [    EVAL] - [dev dataset evaluation result] loss=0.16528 f1=0.92512 matthews=0.91190 acc=0.97750 [step/sec: 11.46]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:02,094] [   TRAIN] - step 1810 / 4000: loss=0.00010 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:05,065] [   TRAIN] - step 1820 / 4000: loss=0.00014 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:08,034] [   TRAIN] - step 1830 / 4000: loss=0.02940 f1=0.97778 matthews=0.97447 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:11,005] [   TRAIN] - step 1840 / 4000: loss=0.00298 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:13,977] [   TRAIN] - step 1850 / 4000: loss=0.00016 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:00:13,978] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:00:24,856] [    EVAL] - [dev dataset evaluation result] loss=0.16099 f1=0.91792 matthews=0.90361 acc=0.97550 [step/sec: 11.56]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:27,828] [   TRAIN] - step 1860 / 4000: loss=0.03859 f1=0.96774 matthews=0.96490 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:30,795] [   TRAIN] - step 1870 / 4000: loss=0.07549 f1=0.95652 matthews=0.95046 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:33,766] [   TRAIN] - step 1880 / 4000: loss=0.00031 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:36,739] [   TRAIN] - step 1890 / 4000: loss=0.00034 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:39,709] [   TRAIN] - step 1900 / 4000: loss=0.00072 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:00:39,711] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:00:50,551] [    EVAL] - [dev dataset evaluation result] loss=0.14778 f1=0.92203 matthews=0.90891 acc=0.97700 [step/sec: 11.54]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:53,522] [   TRAIN] - step 1910 / 4000: loss=0.00021 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:56,492] [   TRAIN] - step 1920 / 4000: loss=0.00666 f1=0.97143 matthews=0.96842 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:00:59,463] [   TRAIN] - step 1930 / 4000: loss=0.00026 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:02,434] [   TRAIN] - step 1940 / 4000: loss=0.00042 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:05,403] [   TRAIN] - step 1950 / 4000: loss=0.00082 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:01:05,404] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:01:16,249] [    EVAL] - [dev dataset evaluation result] loss=0.17427 f1=0.91938 matthews=0.90645 acc=0.97650 [step/sec: 11.53]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:19,221] [   TRAIN] - step 1960 / 4000: loss=0.07803 f1=0.94915 matthews=0.93786 acc=0.98125 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:22,194] [   TRAIN] - step 1970 / 4000: loss=0.02730 f1=0.98361 matthews=0.97995 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:25,165] [   TRAIN] - step 1980 / 4000: loss=0.00161 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:28,137] [   TRAIN] - step 1990 / 4000: loss=0.04414 f1=0.95000 matthews=0.94286 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:31,106] [   TRAIN] - step 2000 / 4000: loss=0.00890 f1=0.98182 matthews=0.97828 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:01:31,107] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:01:41,934] [    EVAL] - [dev dataset evaluation result] loss=0.17459 f1=0.91096 matthews=0.89648 acc=0.97400 [step/sec: 11.56]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:44,917] [   TRAIN] - step 2010 / 4000: loss=0.00027 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:47,890] [   TRAIN] - step 2020 / 4000: loss=0.03276 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:50,857] [   TRAIN] - step 2030 / 4000: loss=0.00031 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:53,828] [   TRAIN] - step 2040 / 4000: loss=0.01727 f1=0.97436 matthews=0.97122 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:01:56,797] [   TRAIN] - step 2050 / 4000: loss=0.00007 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:01:56,798] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:02:07,536] [    EVAL] - [dev dataset evaluation result] loss=0.16970 f1=0.92000 matthews=0.90591 acc=0.97600 [step/sec: 11.65]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:10,506] [   TRAIN] - step 2060 / 4000: loss=0.00023 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:13,475] [   TRAIN] - step 2070 / 4000: loss=0.00022 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:16,443] [   TRAIN] - step 2080 / 4000: loss=0.00014 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:19,413] [   TRAIN] - step 2090 / 4000: loss=0.00019 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:22,385] [   TRAIN] - step 2100 / 4000: loss=0.00160 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:02:22,386] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:02:33,221] [    EVAL] - [dev dataset evaluation result] loss=0.16699 f1=0.92749 matthews=0.91509 acc=0.97850 [step/sec: 11.55]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:36,191] [   TRAIN] - step 2110 / 4000: loss=0.00040 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:39,158] [   TRAIN] - step 2120 / 4000: loss=0.00004 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:42,129] [   TRAIN] - step 2130 / 4000: loss=0.00015 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:45,102] [   TRAIN] - step 2140 / 4000: loss=0.00189 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:02:48,071] [   TRAIN] - step 2150 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:02:48,072] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:02:58,891] [    EVAL] - [dev dataset evaluation result] loss=0.18009 f1=0.91973 matthews=0.90569 acc=0.97600 [step/sec: 11.58]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:01,863] [   TRAIN] - step 2160 / 4000: loss=0.00045 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:04,836] [   TRAIN] - step 2170 / 4000: loss=0.00652 f1=0.97778 matthews=0.97447 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:07,809] [   TRAIN] - step 2180 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:10,779] [   TRAIN] - step 2190 / 4000: loss=0.00007 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:13,751] [   TRAIN] - step 2200 / 4000: loss=0.00015 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:03:13,752] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:03:24,581] [    EVAL] - [dev dataset evaluation result] loss=0.17674 f1=0.92333 matthews=0.90983 acc=0.97700 [step/sec: 11.57]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:27,551] [   TRAIN] - step 2210 / 4000: loss=0.01038 f1=0.98305 matthews=0.97943 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:30,524] [   TRAIN] - step 2220 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:33,498] [   TRAIN] - step 2230 / 4000: loss=0.00036 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:36,466] [   TRAIN] - step 2240 / 4000: loss=0.00005 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:39,437] [   TRAIN] - step 2250 / 4000: loss=0.00005 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:03:39,438] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:03:50,346] [    EVAL] - [dev dataset evaluation result] loss=0.17827 f1=0.92487 matthews=0.91169 acc=0.97750 [step/sec: 11.49]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:53,316] [   TRAIN] - step 2260 / 4000: loss=0.00007 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:56,287] [   TRAIN] - step 2270 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:03:59,255] [   TRAIN] - step 2280 / 4000: loss=0.04715 f1=0.97778 matthews=0.97447 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:02,224] [   TRAIN] - step 2290 / 4000: loss=0.00008 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:05,195] [   TRAIN] - step 2300 / 4000: loss=0.00008 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:04:05,196] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:04:16,019] [    EVAL] - [dev dataset evaluation result] loss=0.17109 f1=0.91980 matthews=0.90543 acc=0.97550 [step/sec: 11.57]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:18,986] [   TRAIN] - step 2310 / 4000: loss=0.05357 f1=0.97561 matthews=0.97241 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:21,956] [   TRAIN] - step 2320 / 4000: loss=0.00027 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:24,925] [   TRAIN] - step 2330 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:27,895] [   TRAIN] - step 2340 / 4000: loss=0.07923 f1=0.96774 matthews=0.96077 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:30,863] [   TRAIN] - step 2350 / 4000: loss=0.00079 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:04:30,864] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:04:41,800] [    EVAL] - [dev dataset evaluation result] loss=0.15906 f1=0.91558 matthews=0.90046 acc=0.97400 [step/sec: 11.44]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:44,772] [   TRAIN] - step 2360 / 4000: loss=0.00034 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:47,744] [   TRAIN] - step 2370 / 4000: loss=0.00543 f1=0.97872 matthews=0.97537 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:50,714] [   TRAIN] - step 2380 / 4000: loss=0.04809 f1=0.95652 matthews=0.95046 acc=0.98750 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:53,686] [   TRAIN] - step 2390 / 4000: loss=0.00081 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:04:56,660] [   TRAIN] - step 2400 / 4000: loss=0.00090 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:04:56,661] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:05:07,566] [    EVAL] - [dev dataset evaluation result] loss=0.18964 f1=0.90625 matthews=0.89196 acc=0.97300 [step/sec: 11.47]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:10,535] [   TRAIN] - step 2410 / 4000: loss=0.00398 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:13,506] [   TRAIN] - step 2420 / 4000: loss=0.00008 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:16,477] [   TRAIN] - step 2430 / 4000: loss=0.00020 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:19,446] [   TRAIN] - step 2440 / 4000: loss=0.00005 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:22,413] [   TRAIN] - step 2450 / 4000: loss=0.00020 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:05:22,414] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:05:33,322] [    EVAL] - [dev dataset evaluation result] loss=0.17034 f1=0.92617 matthews=0.91336 acc=0.97800 [step/sec: 11.47]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:36,292] [   TRAIN] - step 2460 / 4000: loss=0.00006 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:39,263] [   TRAIN] - step 2470 / 4000: loss=0.00004 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:42,231] [   TRAIN] - step 2480 / 4000: loss=0.00992 f1=0.98039 matthews=0.97694 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:45,200] [   TRAIN] - step 2490 / 4000: loss=0.00005 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:05:48,172] [   TRAIN] - step 2500 / 4000: loss=0.02842 f1=0.97959 matthews=0.97619 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:05:48,174] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-02-28 20:05:59,011] [    EVAL] - [dev dataset evaluation result] loss=0.18027 f1=0.91722 matthews=0.90250 acc=0.97500 [step/sec: 11.54]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:06:01,996] [   TRAIN] - step 2510 / 4000: loss=0.00007 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.36]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:06:04,964] [   TRAIN] - step 2520 / 4000: loss=0.01846 f1=0.97143 matthews=0.96842 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:06:07,935] [   TRAIN] - step 2530 / 4000: loss=0.02893 f1=0.98246 matthews=0.97888 acc=0.99375 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:06:10,908] [   TRAIN] - step 2540 / 4000: loss=0.00005 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[36m[2020-02-28 20:06:13,876] [   TRAIN] - step 2550 / 4000: loss=0.00042 f1=1.00000 matthews=1.00000 acc=1.00000 [step/sec: 3.37]\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:06:13,877] [    INFO] - Evaluation on dev dataset start\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33eafd68b5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36mfinetune_and_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinetune_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(self, do_eval)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                     \u001b[0mrun_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, do_eval)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_program\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_program\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pyreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_py_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_data_feeder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36m_run_with_py_reader\u001b[0;34m(self, do_eval)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdo_eval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_interval_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_step_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_run_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36mhook_function\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36m_default_eval_interval_event\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_eval_interval_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_run_step_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, phase, load_best_model)\u001b[0m\n\u001b[1;32m    797\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_if_necessary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_start_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mrun_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_end_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, do_eval)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_program\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_program\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pyreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_py_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_data_feeder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/finetune/task/base_task.py\u001b[0m in \u001b[0;36m_run_with_py_reader\u001b[0;34m(self, do_eval)\u001b[0m\n\u001b[1;32m    904\u001b[0m                         fetch_result = self.exe.run(\n\u001b[1;32m    905\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_program_to_be_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m                             fetch_list=self.fetch_list)\n\u001b[0m\u001b[1;32m    907\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                         fetch_result = self.exe.run(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOFException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_impl\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mfetch_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mfetch_var_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_var_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 return_numpy=return_numpy)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     def _run_program(self, program, feed, fetch_list, feed_var_name,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_parallel\u001b[0;34m(self, program, scope, feed, fetch_list, fetch_var_name, return_numpy)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mfetch_var_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_name_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_var_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_states = cls_task.finetune_and_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 八、使用模型进行预测\n",
    "\n",
    "当Finetune完成后，我们使用模型来进行预测，完整预测代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 20:06:33,899] [    INFO] - The best model has been loaded\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:06:33,900] [    INFO] - PaddleHub predict start\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:06:44,984] [    INFO] - PaddleHub predict finished.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### predict Dataset\n",
    "f=open(\"data/valid_split.csv\",\"r\")\n",
    "data1=[]\n",
    "labels=[]\n",
    "for index,line in enumerate(f.readlines()):\n",
    "    if index==0:\n",
    "        continue\n",
    "    line= line.replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\",\")\n",
    "    label=int(line[0])\n",
    "    comment=line[1]\n",
    "    labels.append(label)\n",
    "    data1.append([comment])\n",
    "f.close()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Data to be prdicted\n",
    "pred=[]\n",
    "index = 0\n",
    "run_states = cls_task.predict(data=data1)\n",
    "results = [run_state.run_results for run_state in run_states]\n",
    "for batch_result in results:\n",
    "    # get predict index\n",
    "    batch_result = np.argmax(batch_result, axis=2)[0]\n",
    "    for result in batch_result:\n",
    "        # print(\"%s\\tpredict=%s\" % (data1[index], result))\n",
    "        pred.append(result)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(275, 302, 1960, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=np.array(pred)\n",
    "labels=np.array(labels)\n",
    "sum(pred[[pred==labels]]),sum(labels),sum(pred==labels),2000-sum(pred==labels)-(sum(labels)-sum(pred[[pred==labels]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### predict Dataset\n",
    "#### predict Dataset\n",
    "f=open(\"data/test_new.csv\",\"r\")\n",
    "data1=[]\n",
    "labels=[]\n",
    "for index,line in enumerate(f.readlines()):\n",
    "    if index==0:\n",
    "        continue\n",
    "    line= line.replace(\"\\n\",\" \").replace(\" \",\"\").strip().split(\",\")\n",
    "    label=line[0]\n",
    "    comment=line[1]\n",
    "    labels.append(label)\n",
    "    data1.append([comment])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-02-28 20:06:53,983] [    INFO] - The best model has been loaded\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:06:53,985] [    INFO] - PaddleHub predict start\u001b[0m\n",
      "\u001b[32m[2020-02-28 20:07:04,815] [    INFO] - PaddleHub predict finished.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# Data to be prdicted\r\n",
    "pred=[]\r\n",
    "index = 0\r\n",
    "run_states = cls_task.predict(data=data1)\r\n",
    "results = [run_state.run_results for run_state in run_states]\r\n",
    "for batch_result in results:\r\n",
    "    # get predict index\r\n",
    "    batch_result = np.argmax(batch_result, axis=2)[0]\r\n",
    "    for result in batch_result:\r\n",
    "        # print(\"%s\\tpredict=%s\" % (data1[index], result))\r\n",
    "        pred.append(result)\r\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_file=\"data/sample.csv\"\n",
    "df_sample=pd.read_csv(sample_file, delimiter=\",\")\n",
    "df_sample[\"label\"]=np.array(pred)\n",
    "df_sample.to_csv(\"answer.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}